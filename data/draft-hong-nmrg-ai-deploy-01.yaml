---
id: drafthongnmrgaideploy01
type: standard
schema_version: v1.4.1
title:
- language: en
  script: Latn
  content: Considerations of deploying AI services in a distributed approach
source:
- type: src
  content: https://datatracker.ietf.org/doc/html/draft-hong-nmrg-ai-deploy-01
docidentifier:
- content: draft-hong-nmrg-ai-deploy
  type: Internet-Draft
- content: draft-hong-nmrg-ai-deploy-01
  type: Internet-Draft
  primary: true
docnumber: I-D.hong-nmrg-ai-deploy
date:
- type: published
  at: '2022-07-11'
contributor:
- role:
  - type: author
  person:
    name:
      forename:
      - language: en
        script: Latn
        initial: "Y"
      formatted_initials:
        language: en
        content: Y.
      surname:
        language: en
        content: Hong
      completename:
        language: en
        content: Yong-Geun Hong
    affiliation:
    - organization:
        name:
        - language: en
          content: Daejeon University
- role:
  - type: author
  person:
    name:
      forename:
      - language: en
        script: Latn
        initial: J
      formatted_initials:
        language: en
        content: J.
      surname:
        language: en
        content: Youn
      completename:
        language: en
        content: Joo-Sang Youn
    affiliation:
    - organization:
        name:
        - language: en
          content: DONG-EUI Univ
- role:
  - type: author
  person:
    name:
      forename:
      - language: en
        script: Latn
        initial: H
      formatted_initials:
        language: en
        content: H.
      surname:
        language: en
        content: Kahng
      completename:
        language: en
        content: Hyun-Kook Kahng
    affiliation:
    - organization:
        name:
        - language: en
          content: Korea University
version:
- draft: '01'
language:
- en
script:
- Latn
abstract:
- language: en
  script: Latn
  content: "   As the development of AI technology matured and AI technology began\n
    \  to be applied in various fields, AI technology is changed from\n   running
    only on very high-performance servers with small hardware,\n   including microcontrollers,
    low-performance CPUs and AI chipsets.  In\n   this document, we consider how to
    configure the system in terms of AI\n   inference service to provide AI service
    in a distributed approach.\n   Also, we describe the points to be considered in
    the environment\n   where a client connects to a cloud server and an edge device
    and\n   requests an AI service.\n\n\t "
relation:
- type: updates
  bibitem:
    formattedref: draft-hong-nmrg-ai-deploy-00
    source:
    - type: src
      content: https://datatracker.ietf.org/doc/html/draft-hong-nmrg-ai-deploy-00
    docidentifier:
    - content: draft-hong-nmrg-ai-deploy-00
      type: Internet-Draft
      primary: true
- type: updatedBy
  bibitem:
    formattedref: draft-hong-nmrg-ai-deploy-02
    source:
    - type: src
      content: https://datatracker.ietf.org/doc/html/draft-hong-nmrg-ai-deploy-02
    docidentifier:
    - content: draft-hong-nmrg-ai-deploy-02
      type: Internet-Draft
      primary: true
series:
- type: main
  title:
  - language: en
    script: Latn
    content: Internet-Draft
  number: draft-hong-nmrg-ai-deploy-01
ext:
  schema_version: v1.0.1
  doctype:
    content: internet-draft
  flavor: ietf
