---
schema-version: v1.2.9
id: draft-kompella-rtgwg-mlnwsched-01
title:
- content: Scheduling Network Resources for Machine Learning Clusters
  language:
  - en
  script:
  - Latn
  format: text/plain
link:
- content: https://datatracker.ietf.org/doc/html/draft-kompella-rtgwg-mlnwsched-01
  type: src
type: standard
docid:
- id: draft-kompella-rtgwg-mlnwsched-01
  type: Internet-Draft
  primary: true
- id: I-D.kompella-rtgwg-mlnwsched
  type: IETF
  scope: anchor
docnumber: I-D.kompella-rtgwg-mlnwsched
date:
- type: published
  value: '2025-11-02'
contributor:
- person:
    name:
      given:
        forename:
        - content: Kireeti
          language:
          - en
        - content:
          language:
          - en
          initial: K
        formatted_initials:
          content: K.
          language:
          - en
      surname:
        content: Kompella
        language:
        - en
      completename:
        content: Kireeti Kompella
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Juniper Networks
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Vishnu
          language:
          - en
        - content:
          language:
          - en
          initial: V
        - content:
          language:
          - en
          initial: P
        formatted_initials:
          content: V. P.
          language:
          - en
      surname:
        content: Beeram
        language:
        - en
      completename:
        content: Vishnu Pavan Beeram
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Juniper Networks
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Aditya
          language:
          - en
        - content:
          language:
          - en
          initial: A
        formatted_initials:
          content: A.
          language:
          - en
      surname:
        content: Mahale
        language:
        - en
      completename:
        content: Aditya Mahale
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Cerebras Systems
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Raghav
          language:
          - en
        - content:
          language:
          - en
          initial: R
        formatted_initials:
          content: R.
          language:
          - en
      surname:
        content: Bhargava
        language:
        - en
      completename:
        content: Raghav Bhargava
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Crusoe
  role:
  - type: author
version:
- draft: '01'
revdate: '2025-11-02'
language:
- en
script:
- Latn
abstract:
- content: '<p>Large Language Models (LLMs) are pushing the boundaries of technology.
    The scale that they have reached currently vastly exceeds the capacity of any
    single compute unit (XPU); this requires a distributed approach where multiple
    XPUs are connected via a "backend" network, sometimes in a single data center,
    but increasingly in multiple data centers connected by a "data center interconnect"
    (DCI). We are approaching the point where the scale exceeds that of a single data
    center, thus requiring multiple such data centers connected via a "data center
    interconnect" network. Training and inferencing are expensive and critical operations,
    thus they are typically scheduled, i.e., the (compute) resources they need are
    carefully estimated, allocated and deployed so that these resources are efficiently
    used. However, while compute investment in these LLM processing clusters dwarfs
    that of networks, it is becoming increasingly clear that the latter can greatly
    impact the former. This has been the focus of recent conferences, including the
    fantel Birds of a Feather meeting in IETF 123, @Scale: Networking 2025 and Open
    Compute Project 2025. This memo proposes that the same care that is taken regarding
    allocation of compute resources to jobs be taken with networking resources: that
    they are estimated, allocated and deployed alongside compute resources; that they
    have contingency plans in case of network glitches; and that a holistic view be
    taken in order to optimize job completion times of training and inferencing jobs.</p>'
  language:
  - en
  script:
  - Latn
  format: text/html
relation:
- type: updates
  bibitem:
    id: draft-kompella-rtgwg-mlnwsched-00
    docid:
    - id: draft-kompella-rtgwg-mlnwsched-00
      type: Internet-Draft
      primary: true
    formattedref:
      content: draft-kompella-rtgwg-mlnwsched-00
      format: text/plain
series:
- type: main
  title:
    content: Internet-Draft
    language:
    - en
    script:
    - Latn
    format: text/plain
  number: draft-kompella-rtgwg-mlnwsched-01
ext:
  schema-version: v1.0.1
  doctype:
    type: internet-draft
