---
schema-version: v1.2.9
id: draft-wang-cats-innetwork-infer-00
title:
- content: In-Network Intelligence for Distributed Collaborative Inference Acceleration
  language:
  - en
  script:
  - Latn
  format: text/plain
link:
- content: https://datatracker.ietf.org/doc/html/draft-wang-cats-innetwork-infer-00
  type: src
type: standard
docid:
- id: draft-wang-cats-innetwork-infer-00
  type: Internet-Draft
  primary: true
- id: I-D.wang-cats-innetwork-infer
  type: IETF
  scope: anchor
docnumber: I-D.wang-cats-innetwork-infer
date:
- type: published
  value: '2025-09-15'
contributor:
- person:
    name:
      given:
        forename:
        - content: Hanling
          language:
          - en
        - content:
          language:
          - en
          initial: H
        formatted_initials:
          content: H.
          language:
          - en
      surname:
        content: Wang
        language:
        - en
      completename:
        content: Hanling Wang
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Pengcheng Laboratory
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Qing
          language:
          - en
        - content:
          language:
          - en
          initial: Q
        formatted_initials:
          content: Q.
          language:
          - en
      surname:
        content: Li
        language:
        - en
      completename:
        content: Qing Li
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Pengcheng Laboratory
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Yong
          language:
          - en
        - content:
          language:
          - en
          initial: Y
        formatted_initials:
          content: Y.
          language:
          - en
      surname:
        content: Jiang
        language:
        - en
      completename:
        content: Yong Jiang
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Tsinghua Shenzhen International Graduate School, Pengcheng Laboratory
  role:
  - type: author
version:
- draft: '00'
revdate: '2025-09-15'
language:
- en
script:
- Latn
abstract:
- content: "<p>The rapid proliferation of deep learning models has led to growing
    demands for low-latency and high-throughput inference across heterogeneous environments.
    While edge devices often host data sources, their limited compute and network
    resources restrict efficient model inference. Cloud servers provide abundant capacity
    but suffer from transmission delays and bottlenecks. Emerging programmable in-network
    devices (e.g., switches, FPGAs, SmartNICs) offer a unique opportunity to accelerate
    inference by processing tasks directly along data paths. This document introduces
    an architecture for _Distributed Collaborative Inference Acceleration_. It proposes
    mechanisms to split, offload, and coordinate inference workloads across edge devices,
    in-network resources, and cloud servers, enabling reduced response time and improved
    utilization.</p>"
  language:
  - en
  script:
  - Latn
  format: text/html
series:
- type: main
  title:
    content: Internet-Draft
    language:
    - en
    script:
    - Latn
    format: text/plain
  number: draft-wang-cats-innetwork-infer-00
ext:
  schema-version: v1.0.1
  doctype:
    type: internet-draft
